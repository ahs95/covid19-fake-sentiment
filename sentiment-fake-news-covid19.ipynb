{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12932426,"sourceType":"datasetVersion","datasetId":8180840}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"86fc7862-1be9-45cf-9db7-17be3a54ea94","_cell_guid":"7a3632c5-1ee5-4055-a70a-80fd5859fa66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/csebuetnlp/normalizer\n!pip install transformers openpyxl tqdm datasets scikit-learn gradio torch accelerate -q","metadata":{"_uuid":"790e5ddb-413a-4cdd-a029-646c3ccab810","_cell_guid":"550bba46-04de-4683-a852-47f65506dc00","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math, json, re, random, time, gc\nfrom dataclasses import dataclass\nfrom typing import List, Dict, Optional\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup, AutoConfig, PreTrainedModel, PretrainedConfig\n\nfrom normalizer import normalize\nfrom multiprocessing import Pool, cpu_count\nimport shutil\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"65dcc6e0-8875-4808-86b0-dba1b0da913b","_cell_guid":"7281041b-71c8-40ed-bed8-da5f1e58162b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True  # Faster convolutions for fixed input sizes\ntorch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 for matmul (faster)\ntorch.backends.cudnn.allow_tf32 = True  # Allow TF32 for convolutions","metadata":{"_uuid":"7062c431-19e4-46c9-8795-222eecfd1783","_cell_guid":"64ce1a09-e1e8-4851-9744-a775f892b77e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {DEVICE}\")","metadata":{"_uuid":"75fd1d44-676d-421f-a354-c71b0c82aff8","_cell_guid":"26b2efbe-a2dc-4fc1-be82-a4def25942c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----- Paths -----\nEXCEL_PATH = \"/kaggle/input/data-covid-sa-fake-sentiment/data-covid-sa-fake-sentiment.xlsx\"  # change if needed\nSAVE_DIR   = \"/kaggle/working/banglabert_multitask\"\nos.makedirs(SAVE_DIR, exist_ok=True)","metadata":{"_uuid":"34fa46a0-5656-44ef-bb5b-4107577a8215","_cell_guid":"354f17ab-8f3c-40ca-9f79-23ee42607317","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----- Hyperparameters -----\nMODEL_NAME = \"csebuetnlp/banglabert\"\nMAX_LENGTH = 512\nBATCH_SIZE = 16\nGRAD_ACCUM_STEPS = 4\nEPOCHS = 8\nFIXED_LR = 2e-5\nFIXED_SMOOTHING = 0.1\nWARMUP_RATIO = 0.06\nWEIGHT_DECAY = 0.01\nALPHA_SENTIMENT = 0.75\nDEBUG_MODE = False  # Set to True for quick testing\n\n# Optional gradient checkpointing (set to True only if OOM)\nUSE_GRAD_CHECKPOINT = False","metadata":{"_uuid":"0ee05b1a-17d6-49ac-8047-479b48bc826a","_cell_guid":"67e3e94d-9e21-4910-85da-8250c2d3361e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SENTIMENT_MAP = {\"negative\":0, \"neutral\":1, \"positive\":2}\nTRUTH_MAP     = {\"fake\":0, \"real\":1}","metadata":{"_uuid":"0665a744-ab91-46ba-89fe-e0156d296788","_cell_guid":"d5c89179-4390-4877-9826-794d2f7e3f0d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reverse maps for decoding\nidx2sent = {v: k for k, v in SENTIMENT_MAP.items()}\nidx2truth = {v: k for k, v in TRUTH_MAP.items()}","metadata":{"_uuid":"008c41bf-cc96-4b63-b840-39cf06313752","_cell_guid":"bb144e7b-9771-472c-8d43-9a54bffd8d06","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_excel(EXCEL_PATH)","metadata":{"_uuid":"53057c1d-81ec-464d-938d-e99c61eb2348","_cell_guid":"784d68c9-677f-4e30-a7a8-b336125ea525","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# keep first occurrence of exact duplicates (text + both labels identical)\ndf = df.drop_duplicates(subset=[\"text\", \"sentiment\", \"truthfulness\"], keep=\"first\")","metadata":{"_uuid":"c3dac023-d519-4544-af61-7dbe7246039b","_cell_guid":"f117d068-f26c-4d52-b34e-abf06693e639","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. Basic Overview ---\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nColumn names:\", df.columns.tolist())\nprint(\"\\nData types:\\n\", df.dtypes)\nprint(\"\\nMissing values:\\n\", df.isnull().sum())\nprint(\"\\nSample rows:\\n\", df.head())","metadata":{"_uuid":"c930b4b0-3b8b-4f92-95d3-732656f5cee4","_cell_guid":"a424a247-b61d-40b0-b421-28f43fc9b063","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['sentiment'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['truthfulness'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. Sentiment Distribution ---\nplt.figure(figsize=(6,4))\nsns.countplot(x='sentiment', data=df, order=df['sentiment'].value_counts().index)\nplt.title(\"Sentiment Distribution\")\nplt.show()","metadata":{"_uuid":"91e93deb-1677-43d9-a702-add6ff456300","_cell_guid":"539e0bcb-f509-4d1d-b25a-fa7ead798ece","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. Fake vs Real Distribution ---\nplt.figure(figsize=(6,4))\nsns.countplot(x='truthfulness', data=df)\nplt.title(\"Fake vs Real Posts\")\nplt.show()","metadata":{"_uuid":"c873da07-5be1-4f64-a4da-bc2238c8ee65","_cell_guid":"12990147-d2e2-4990-946f-836ec43ebdbc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Crosstab of Fake/Real vs Sentiment\ncross_tab = pd.crosstab(df['sentiment'], df['truthfulness'])\ncross_tab.plot(kind='bar', stacked=True, figsize=(8,5), colormap='viridis')\nplt.title(\"Sentiment vs Truthfulness\")\nplt.show()","metadata":{"_uuid":"dc663dd9-d48d-41e2-b8c9-1eefcc962cb0","_cell_guid":"5ccaa36f-6d74-48da-aa8c-ac376610439d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. Text Length Analysis ---\ndf['char_count'] = df['text'].apply(len)\ndf['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n\nplt.figure(figsize=(8,4))\nsns.histplot(df['word_count'], bins=30, kde=True)\nplt.title(\"Distribution of Post Word Counts\")\nplt.show()\n\nplt.figure(figsize=(8,4))\nsns.boxplot(x='sentiment', y='word_count', data=df)\nplt.title(\"Post Length by Sentiment\")\nplt.show()","metadata":{"_uuid":"5365b62b-30d6-4b79-917a-0729a36d41ee","_cell_guid":"d8fa8cdf-4939-4d63-b312-f731b5568d62","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 7. Heatmap: Sentiment vs Fake/Real ---\nplt.figure(figsize=(6,4))\nsns.heatmap(cross_tab, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Heatmap: Sentiment vs Fake/Real\")\nplt.show()","metadata":{"_uuid":"dcc3e08e-25f2-44f5-829e-adbadf9492cb","_cell_guid":"33a0bbfd-edeb-40f3-9015-8d2f1a11c438","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1️⃣ Compile the “whitespace‑collapse” regex once (global)\n_COLLAPSE_RE = re.compile(r\"\\s+\")\n\ndef _clean_one(text: str) -> str:\n    \"\"\"\n    Normalise a **single** string, then collapse whitespace and strip.\n    This function is deliberately tiny – it will be executed in a separate\n    process, so we want to avoid any heavy imports inside it.\n    \"\"\"\n    txt = normalize(\n        text,\n        unicode_norm=\"NFKC\",\n        punct_replacement=None,\n        url_replacement=\"\",\n        emoji_replacement=\"\",\n        apply_unicode_norm_last=True,\n    )\n    # Collapse any run of whitespace into a single space\n    txt = _COLLAPSE_RE.sub(\" \", txt).strip()\n    return txt","metadata":{"_uuid":"c465df4d-b1d5-4f31-8e67-ae3b41719b8c","_cell_guid":"20c24b38-b55d-47be-8c44-3007d5a34ff2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _batch_normalize(texts):\n    \"\"\"\n    Wrapper that receives a *list* of strings (one chunk) and returns the\n    cleaned list.  It is executed in a worker process.\n    \"\"\"\n    return [_clean_one(t) for t in texts]","metadata":{"_uuid":"80f7900f-cae2-4b47-b487-6e433b216487","_cell_guid":"083cd1b5-4d7c-404f-aacc-80e2057131f4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parallel_preprocess(text_series, n_jobs: int = None, chunk_size: int = 2000):\n    \"\"\"\n    Fast multi‑process preprocessing.\n\n    Parameters\n    ----------\n    text_series : pd.Series\n        Column that contains raw text.\n    n_jobs : int, optional\n        Number of worker processes – default = half of the available CPUs.\n    chunk_size : int, optional\n        How many rows are sent to a worker at once.  Larger chunks → less\n        inter‑process communication overhead.\n\n    Returns\n    -------\n    pd.Series\n        Cleaned text, same length as the input.\n    \"\"\"\n    if n_jobs is None:\n        # Colab free tier typically has 2 vCPU → use 1 or 2 processes.\n        n_jobs = max(1, cpu_count() // 2)\n\n    # Convert to a plain list of strings (ensures no NaNs)\n    raw_texts = text_series.astype(str).tolist()\n\n    # ------------------------------------------------------------------\n    # 2️⃣ Split the list into chunks (roughly `len(raw_texts) / n_jobs`)\n    # ------------------------------------------------------------------\n    total = len(raw_texts)\n    if total == 0:\n        return pd.Series([], dtype=str)\n\n    # Calculate optimal chunk size if not supplied\n    if chunk_size is None:\n        chunk_size = max(1, total // (n_jobs * 4))\n\n    # Build list of slices\n    chunks = [raw_texts[i : i + chunk_size] for i in range(0, total, chunk_size)]\n\n    # ------------------------------------------------------------------\n    # 3️⃣ Run the heavy work in parallel\n    # ------------------------------------------------------------------\n    print(f\"🔧 Pre‑processing {total:,} rows with {n_jobs} process(es) \"\n          f\"(chunk size ≈ {chunk_size}) …\")\n    with Pool(processes=n_jobs) as pool:\n        # `imap_unordered` yields results as soon as a worker finishes a chunk\n        cleaned_chunks = list(pool.imap_unordered(_batch_normalize, chunks, chunksize=1))\n\n    # ------------------------------------------------------------------\n    # 4️⃣ Flatten the list of chunks back into one list and wrap as Series\n    # ------------------------------------------------------------------\n    cleaned_texts = [txt for chunk in cleaned_chunks for txt in chunk]\n\n    # Verify length sanity (helps catching bugs early)\n    assert len(cleaned_texts) == total, (\n        f\"Length mismatch after cleaning: expected {total}, got {len(cleaned_texts)}\"\n    )\n    return pd.Series(cleaned_texts, index=text_series.index)","metadata":{"_uuid":"5c967d91-5ed0-497c-9549-19359851b01d","_cell_guid":"62b9a358-5461-44ec-90ba-a6eb18d17097","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load custom stop words from a file\ndef load_custom_stop_words(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        stop_words = set(file.read().splitlines())\n    return stop_words\n\nstop_words_file_path = '/kaggle/input/data-covid-sa-fake-sentiment/Stopwords.txt'\ncustom_stop_words = load_custom_stop_words(stop_words_file_path)","metadata":{"_uuid":"7c17ab09-0bfa-44df-91ea-f1a0ff0ee4a7","_cell_guid":"c2421375-27c6-4438-821e-2f3f659d096c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def stopwords_removal(text):\n    text = ' '.join([word for word in text.split() if word.lower() not in custom_stop_words])\n    return text\n\ndf['text'] = df['text'].astype(str).apply(stopwords_removal)\ndf = df[df['text'].str.strip() != \"\"]","metadata":{"_uuid":"e5d93def-e0f2-4a80-b75f-e5d3d7ae2836","_cell_guid":"aa79a0b4-f09f-469b-b00c-d2e92adbf4c5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Usage\ndf[\"text\"] = parallel_preprocess(df[\"text\"])","metadata":{"_uuid":"c9891ffa-317f-49f6-b4a8-95eded09e4e0","_cell_guid":"5a24d476-35fc-471d-a972-5a61b3eeeca6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SENTIMENT_ALIASES = {\n    \"pos\":\"positive\", \"positive\":\"positive\",\n    \"neg\":\"negative\", \"negative\":\"negative\",\n    \"neu\":\"neutral\",  \"neutral\":\"neutral\",\n    \"Positive\":\"positive\", \"Neutral\":\"neutral\", \"Negative\":\"negative\"\n}\nTRUTH_ALIASES = {\n    \"fake\":\"fake\",\"fake news\":\"fake\",\"false\":\"fake\",\n    \"real\":\"real\",\"true\":\"real\",\"true news\":\"real\"\n}","metadata":{"_uuid":"b198dd85-07e8-4b92-8e0c-4290f6feb00e","_cell_guid":"688e09fa-5e73-4ba4-99ea-1b28cd261f0f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_series_lower(series, label_map, aliases, colname):\n    encoded = []\n    bad_items = {}\n    for i, orig in enumerate(series):\n        key = str(orig).strip().lower()\n        key = aliases.get(key, key)\n        val = label_map.get(key)\n        if val is None:\n            bad_items[orig] = key\n        encoded.append(val)\n    if bad_items:\n        raise ValueError(f\"Unmapped labels in {colname}: {bad_items}\")\n    return np.array(encoded, dtype=np.int64)\n\ny_s = encode_series_lower(df[\"sentiment\"], SENTIMENT_MAP, SENTIMENT_ALIASES, \"sentiment\")\ny_t = encode_series_lower(df[\"truthfulness\"], TRUTH_MAP, TRUTH_ALIASES, \"truthfulness\")","metadata":{"_uuid":"11c10003-e4f5-4895-b3ff-cb7ac1b16c26","_cell_guid":"f618f42b-1a22-4c85-97f5-38b4ef5cd9f7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train/val/test split\ndf_train, df_temp, y_s_train, y_s_temp, y_t_train, y_t_temp = train_test_split(\n    df, y_s, y_t, test_size=0.2, random_state=SEED, stratify=y_s\n)\ndf_val, df_test, y_s_val, y_s_test, y_t_val, y_t_test = train_test_split(\n    df_temp, y_s_temp, y_t_temp, test_size=0.5, random_state=SEED, stratify=y_s_temp\n)\n\nprint(\"Train:\", df_train.shape, \"Val:\", df_val.shape, \"Test:\", df_test.shape)","metadata":{"_uuid":"f8de50be-f66a-4119-985e-4df35159f88c","_cell_guid":"a9771c6c-3551-4682-a6bd-20c9772bdb81","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Double-check directory exists before saving\nif not os.path.exists(SAVE_DIR):\n    os.makedirs(SAVE_DIR, exist_ok=True)\n    print(f\"Created directory: {SAVE_DIR}\")\n\n# Save label maps\nwith open(os.path.join(SAVE_DIR, \"sentiment_map.json\"), \"w\", encoding=\"utf-8\") as f:\n    json.dump(SENTIMENT_MAP, f, ensure_ascii=False, indent=2)\nwith open(os.path.join(SAVE_DIR, \"truth_map.json\"), \"w\", encoding=\"utf-8\") as f:\n    json.dump(TRUTH_MAP, f, ensure_ascii=False, indent=2)","metadata":{"_uuid":"0f322fa2-4a4f-462f-8827-a5b6c44ffa34","_cell_guid":"4b69b277-3ffe-4a5a-a5d7-b20d1f908880","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"counts = np.bincount(y_s_train, minlength=3)\nfreqs = counts / counts.sum()\ninv = 1.0 / np.clip(freqs, 1e-8, None)\nsent_class_weights = torch.tensor(inv / inv.mean(), dtype=torch.float32, device=DEVICE)\nprint(\"Sentiment counts:\", counts, \" -> class weights:\", sent_class_weights.tolist())\n\nloss_fn_truth = nn.CrossEntropyLoss(label_smoothing=0.0)","metadata":{"_uuid":"69aca312-0240-4f80-976f-52484f5d205d","_cell_guid":"723e518c-9274-459c-8c8a-d8926650717f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"_uuid":"c73585cb-771d-4173-9578-ee8c0b300190","_cell_guid":"48b383ed-6232-44da-9185-2ffa09a09edc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_dataset(df, tokenizer, max_length=MAX_LENGTH, batch_size=512):\n    texts = df[\"text\"].astype(str).tolist()\n    all_input_ids, all_attention_mask = [], []\n    \n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Tokenizing\"):\n        batch = texts[i:i + batch_size]\n        encoded = tokenizer(batch, padding=\"max_length\", truncation=True, \n                           max_length=max_length, return_tensors=\"pt\")\n        all_input_ids.append(encoded[\"input_ids\"])\n        all_attention_mask.append(encoded[\"attention_mask\"])\n    \n    return {\n        \"input_ids\": torch.cat(all_input_ids, dim=0),\n        \"attention_mask\": torch.cat(all_attention_mask, dim=0)\n    }","metadata":{"_uuid":"8609f466-ce87-4eb4-b347-9c878097dbd9","_cell_guid":"5ea644e9-d8ba-4731-abf0-b43ba9901ad8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Caching\nCACHE_DIR = os.path.join(SAVE_DIR, \"tokenized_data\")\nos.makedirs(CACHE_DIR, exist_ok=True)\n\ndef load_or_tokenize(df, tokenizer, split_name):\n    cache_path = os.path.join(CACHE_DIR, f\"{split_name}_encodings.pt\")\n    if os.path.exists(cache_path):\n        print(f\"🔁 Loading cached {split_name}...\")\n        return torch.load(cache_path)\n    print(f\"📝 Tokenizing {split_name}...\")\n    encodings = tokenize_dataset(df, tokenizer, MAX_LENGTH)\n    torch.save(encodings, cache_path)\n    return encodings\n\ntrain_encodings = load_or_tokenize(df_train, tokenizer, \"train\")\nval_encodings = load_or_tokenize(df_val, tokenizer, \"val\")\ntest_encodings = load_or_tokenize(df_test, tokenizer, \"test\")","metadata":{"_uuid":"72bde69d-a686-4bf4-85f0-9d3bf0c76b23","_cell_guid":"7a2b529e-233e-49a8-9a43-edc3916cd6e2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset\nclass PreTokenizedDataset(Dataset):\n    def __init__(self, encodings, y_s, y_t):\n        self.input_ids = encodings[\"input_ids\"]\n        self.attention_mask = encodings[\"attention_mask\"]\n        self.y_s = torch.tensor(y_s, dtype=torch.long)\n        self.y_t = torch.tensor(y_t, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attention_mask[idx], self.y_s[idx], self.y_t[idx]\n\ntrain_ds = PreTokenizedDataset(train_encodings, y_s_train, y_t_train)\nval_ds = PreTokenizedDataset(val_encodings, y_s_val, y_t_val)\ntest_ds = PreTokenizedDataset(test_encodings, y_s_test, y_t_test)\n\n# DataLoader\n@dataclass\nclass Collator:\n    def __call__(self, batch):\n        input_ids, attn_mask, ys, yt = zip(*batch)\n        return torch.stack(input_ids), torch.stack(attn_mask), torch.tensor(ys), torch.tensor(yt)\n\ncollate_fn = Collator()","metadata":{"_uuid":"10b7467a-8275-4259-82b0-d791fd1a52ee","_cell_guid":"561ef4b1-b6c9-4a22-be44-f4debaf3a5c9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n                         collate_fn=collate_fn, num_workers=4,\n                         pin_memory=True, prefetch_factor=2)  \n\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n                       collate_fn=collate_fn, num_workers=4, pin_memory=True)  \n\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n                        collate_fn=collate_fn, num_workers=4, pin_memory=True)","metadata":{"_uuid":"fc835468-8295-4fca-b0cc-a56bce381b9e","_cell_guid":"b8f64e21-a38a-4e60-b145-51665ebd05a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----- Model Definitions -----\nfrom transformers import ElectraConfig\n\nclass BanglaBERTConfig(ElectraConfig):\n    model_type = \"banglabert-multitask\"\n\n    def __init__(\n        self,\n        n_sentiment=3,\n        n_truth=2,\n        dropout=0.1,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.n_sentiment = n_sentiment\n        self.n_truth = n_truth\n        self.dropout = dropout","metadata":{"_uuid":"0a289933-a285-40a5-abe0-10b68c627145","_cell_guid":"69a4ef38-120f-4413-9852-f684f806a86a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BanglaBERTMultiTask(PreTrainedModel):\n    config_class = BanglaBERTConfig\n\n    def __init__(self, config, use_gradient_checkpointing=False):\n        super().__init__(config)\n        self.encoder = AutoModel.from_config(config)  # ✅ Correct way\n        if use_gradient_checkpointing:\n            self.encoder.gradient_checkpointing_enable()\n        self.dropout = nn.Dropout(config.dropout)\n        self.sent_head = nn.Linear(config.hidden_size, config.n_sentiment)\n        self.truth_head = nn.Linear(config.hidden_size, config.n_truth)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        cls = self.dropout(outputs.last_hidden_state[:, 0])\n        s = self.sent_head(cls)\n        t = self.truth_head(cls)\n        if labels is not None:\n            ls = nn.CrossEntropyLoss()(s, labels[0])\n            lt = nn.CrossEntropyLoss()(t, labels[1])\n            loss = ALPHA_SENTIMENT * ls + (1 - ALPHA_SENTIMENT) * lt\n            return (loss, s, t)\n        return (s, t)","metadata":{"_uuid":"3f52310e-0535-4b40-b4b9-181e8feb3254","_cell_guid":"221fd55b-8495-4754-a270-4105e07e8c47","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(MODEL_NAME)\nconfig.update({\"n_sentiment\": 3, \"n_truth\": 2, \"dropout\": 0.1})\nmodel = BanglaBERTMultiTask(config, USE_GRAD_CHECKPOINT).to(DEVICE)","metadata":{"_uuid":"272f9f23-7c53-4b18-81ec-a5f57a312add","_cell_guid":"a8598705-5b3b-4f88-a27f-ba4460fd363c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()  # Disable gradient computation for validation\ndef evaluate_with_loss(model, loader, sent_loss_fn):\n    model.eval()\n    all_s, all_t, all_ps, all_pt = [], [], [], []\n    losses = []\n\n    with autocast():  # Fixed: Removed 'cuda' parameter\n        for b in loader:\n            input_ids, attn_mask, ys, yt = [x.to(DEVICE) for x in b]\n            logits_s, logits_t = model(input_ids, attn_mask)\n            loss_s = sent_loss_fn(logits_s, ys)\n            loss_t = nn.CrossEntropyLoss()(logits_t, yt)\n            loss = ALPHA_SENTIMENT * loss_s + (1 - ALPHA_SENTIMENT) * loss_t\n            losses.append(loss.item())\n            all_s.extend(ys.tolist())\n            all_t.extend(yt.tolist())\n            all_ps.extend(logits_s.argmax(dim=1).tolist())\n            all_pt.extend(logits_t.argmax(dim=1).tolist())\n\n    metrics = {\n        \"val_loss\": float(np.mean(losses)),\n        \"sentiment_f1\": f1_score(all_s, all_ps, average=\"macro\"),\n        \"sentiment_acc\": accuracy_score(all_s, all_ps),\n        \"truth_f1\": f1_score(all_t, all_pt, average=\"macro\"),\n        \"truth_acc\": accuracy_score(all_t, all_pt),\n        \"y_true_s\": all_s,\n        \"y_pred_s\": all_ps,\n        \"y_true_t\": all_t,\n        \"y_pred_t\": all_pt,\n    }\n\n    # Add classification reports\n    metrics[\"sentiment_report\"] = classification_report(\n        all_s, all_ps,\n        target_names=[idx2sent[i] for i in range(len(SENTIMENT_MAP))],\n        output_dict=False\n    )\n    metrics[\"truth_report\"] = classification_report(\n        all_t, all_pt,\n        target_names=[idx2truth[i] for i in range(len(TRUTH_MAP))],\n        output_dict=False\n    )\n\n    return metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_loss(model, train_loader, val_loader, sent_loss_fn, lr, epochs=EPOCHS, save_dir=SAVE_DIR):\n    total_steps = len(train_loader) * epochs // GRAD_ACCUM_STEPS\n    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=WEIGHT_DECAY)\n    sched = get_cosine_schedule_with_warmup(opt, int(WARMUP_RATIO * total_steps), total_steps)\n    scaler = GradScaler()\n    best_f1 = 0.0\n    patience, p_max = 3, 2\n    \n    # Track losses and metrics\n    train_loss_history = []\n    val_loss_history = []\n    val_f1_history = []  # Added to store F1 scores for plotting\n    \n    # Use a simple print-based progress indicator instead of tqdm to avoid conflicts\n    print(f\"Starting training for {epochs} epochs...\")\n    \n    for epoch in range(epochs):\n        model.train()\n        loss_running = 0.0\n        opt.zero_grad()\n        \n        # Simple progress indicator instead of tqdm\n        print(f\"Epoch {epoch+1}/{epochs} - Training: \", end=\"\", flush=True)\n        batch_count = 0\n        \n        for step, batch in enumerate(train_loader):\n            input_ids, attn_mask, ys, yt = [b.to(DEVICE) for b in batch]\n            with autocast():\n                logits_s, logits_t = model(input_ids, attn_mask)\n                loss_s = sent_loss_fn(logits_s, ys)\n                loss_t = loss_fn_truth(logits_t, yt)\n                loss = (ALPHA_SENTIMENT * loss_s + (1 - ALPHA_SENTIMENT) * loss_t) / GRAD_ACCUM_STEPS\n            scaler.scale(loss).backward()\n            loss_running += loss.item()\n            \n            if (step + 1) % GRAD_ACCUM_STEPS == 0:\n                scaler.step(opt)\n                scaler.update()\n                opt.zero_grad()\n                sched.step()\n            \n            # Simple progress indicator\n            batch_count += 1\n            if batch_count % 50 == 0:  # Print progress every 50 batches\n                print(\".\", end=\"\", flush=True)\n        \n        print(\" Done\")\n        avg_train_loss = loss_running / len(train_loader)\n        train_loss_history.append(avg_train_loss)\n        \n        # Clear memory after each epoch\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        # Validation\n        print(f\"Epoch {epoch+1}/{epochs} - Validating: \", end=\"\", flush=True)\n        val_metrics = evaluate_with_loss(model, val_loader, sent_loss_fn)\n        val_loss_history.append(val_metrics[\"val_loss\"])\n        val_f1_history.append(val_metrics[\"sentiment_f1\"])  # Store F1 for plotting\n        \n        print(\"Done\")\n        print(f\"  Train Loss: {avg_train_loss:.4f}, Val Loss: {val_metrics['val_loss']:.4f}, F1: {val_metrics['sentiment_f1']:.3f}\")\n        \n        # Check for overfitting\n        if epoch > 0 and val_loss_history[-1] > val_loss_history[-2] and train_loss_history[-1] < train_loss_history[-2]:\n            print(\"⚠️  Warning: Possible overfitting detected!\")\n        \n        if val_metrics[\"sentiment_f1\"] > best_f1 + 1e-4:\n            best_f1 = val_metrics[\"sentiment_f1\"]\n            patience = p_max\n            model.save_pretrained(save_dir)\n            tokenizer.save_pretrained(save_dir)\n            print(f\"💾 Saved new best model with F1: {best_f1:.4f}\")\n        else:\n            patience -= 1\n            if patience <= 0: \n                print(\"Early stopping triggered\")\n                break\n        print(\"-\" * 50)\n    \n    # Plot training history (optional - can be commented out if causing issues)\n    try:\n        plt.figure(figsize=(12, 4))\n        plt.subplot(1, 2, 1)\n        plt.plot(train_loss_history, label='Train Loss', marker='o')\n        plt.plot(val_loss_history, label='Val Loss', marker='s')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.title('Training History')\n        plt.legend()\n        plt.grid(True)\n        \n        plt.subplot(1, 2, 2)\n        plt.plot(val_f1_history, label='Val F1', color='green', marker='^')\n        plt.xlabel('Epoch')\n        plt.ylabel('F1 Score')\n        plt.title('Validation F1 Score')\n        plt.legend()\n        plt.grid(True)\n        \n        plt.tight_layout()\n        plt.show()\n    except Exception as e:\n        print(f\"Could not generate plots: {e}\")\n        print(\"Training loss history:\", train_loss_history)\n        print(\"Validation loss history:\", val_loss_history)\n        print(\"Validation F1 history:\", val_f1_history)\n    \n    # Return final validation metrics\n    return val_metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\\n--- Training with LR={FIXED_LR}, smoothing={FIXED_SMOOTHING} for {EPOCHS} epochs ---\")\nfinal_model = BanglaBERTMultiTask(config, USE_GRAD_CHECKPOINT).to(DEVICE)\nce_loss_fn = nn.CrossEntropyLoss(weight=sent_class_weights, label_smoothing=FIXED_SMOOTHING)\n\ntrain_with_loss(\n    final_model,\n    train_loader,\n    val_loader,\n    ce_loss_fn,\n    lr=FIXED_LR,\n    epochs=EPOCHS\n)\nfinal_model.save_pretrained(SAVE_DIR)\ntokenizer.save_pretrained(SAVE_DIR)","metadata":{"_uuid":"bd8e351d-bd58-4473-a4b5-75f14dfb2749","_cell_guid":"a1d05469-f329-46f6-b6d2-dc3289688c38","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_custom_model(model_path, device=DEVICE):\n    # Load the original config first\n    config = AutoConfig.from_pretrained(MODEL_NAME)\n    \n    # Add your custom parameters\n    config.n_sentiment = 3\n    config.n_truth = 2\n    config.dropout = 0.1\n    \n    # Create model\n    model = BanglaBERTMultiTask(config)\n    \n    # Find and load the model file (always load to CPU first)\n    model_files = [f for f in os.listdir(model_path) if f.endswith(('.bin', '.safetensors'))]\n    if not model_files:\n        raise FileNotFoundError(f\"No model file found in {model_path}\")\n    \n    model_file = os.path.join(model_path, model_files[0])\n    \n    if model_file.endswith(\".safetensors\"):\n        from safetensors.torch import load_file\n        state_dict = load_file(model_file, device=\"cpu\")\n    else:\n        state_dict = torch.load(model_file, map_location=\"cpu\")\n    \n    # Load weights (use strict=False to be more forgiving)\n    model.load_state_dict(state_dict, strict=False)\n    \n    # Move to target device\n    model.to(device)\n    model.eval()\n    \n    return model","metadata":{"_uuid":"1514ea68-2817-4962-9426-84553cd5d67e","_cell_guid":"64b00601-bb8d-4b8c-aab0-0836489e6ece","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = load_custom_model(SAVE_DIR)","metadata":{"_uuid":"f4288693-0b60-4189-8a91-f6236b42dde4","_cell_guid":"2adfe5e2-d7dd-4ca8-aa60-50429fd24edd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_metrics = evaluate_with_loss(model, test_loader, focal_loss_fn)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL TEST RESULTS - ADVANCED MODEL\")\nprint(\"=\"*60)\nprint(f\"Sentiment  : acc={test_metrics['sentiment_acc']:.3f}, macroF1={test_metrics['sentiment_f1']:.3f}\")\nprint(f\"Truthfulness: acc={test_metrics['truth_acc']:.3f}, macroF1={test_metrics['truth_f1']:.3f}\")\n\nprint(\"\\n\" + \"=\"*40)\nprint(\"SENTIMENT CLASSIFICATION REPORT:\")\nprint(\"=\"*40)\nprint(test_metrics[\"sentiment_report\"])\n\nprint(\"\\n\" + \"=\"*40)\nprint(\"TRUTHFULNESS CLASSIFICATION REPORT:\")\nprint(\"=\"*40)\nprint(test_metrics[\"truth_report\"])\n\n# Detailed analysis\nprint(\"\\n\" + \"=\"*40)\nprint(\"DETAILED PERFORMANCE ANALYSIS:\")\nprint(\"=\"*40)\nsentiment_f1_scores = f1_score(test_metrics['y_true_s'], test_metrics['y_pred_s'], average=None, labels=[0,1,2])\ntruth_f1_scores = f1_score(test_metrics['y_true_t'], test_metrics['y_pred_t'], average=None, labels=[0,1])\n\nprint(f\"Sentiment - Negative: {sentiment_f1_scores[0]:.3f}\")\nprint(f\"Sentiment - Neutral:  {sentiment_f1_scores[1]:.3f}\")\nprint(f\"Sentiment - Positive: {sentiment_f1_scores[2]:.3f}\")\nprint(f\"Truthfulness - Fake:  {truth_f1_scores[0]:.3f}\")\nprint(f\"Truthfulness - Real:  {truth_f1_scores[1]:.3f}\")","metadata":{"_uuid":"ceb648a3-eaed-4e11-a25c-73814bdeffda","_cell_guid":"41c0488d-1cbc-44cc-ad2d-da1527e7a275","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrices\ndef plot_cm(y_true, y_pred, labels, title):\n    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n    plt.figure(figsize=(4.5,4))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(title)\n    plt.tight_layout(); plt.show()\n\nplot_cm(test_metrics[\"y_true_s\"], test_metrics[\"y_pred_s\"], [idx2sent[i] for i in range(3)], \"Sentiment (Test)\")\nplot_cm(test_metrics[\"y_true_t\"], test_metrics[\"y_pred_t\"], [idx2truth[i] for i in range(2)], \"Truthfulness (Test)\")","metadata":{"_uuid":"8f2884f1-fc8f-4fea-8849-390ef0c19324","_cell_guid":"a11ee5c8-f4f6-48cb-aff2-b39f00fe69d2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Error analysis\ndf_err = df_test.copy().reset_index(drop=True)\ndf_err[\"sent_true\"] = [idx2sent[i] for i in test_metrics[\"y_true_s\"]]\ndf_err[\"sent_pred\"] = [idx2sent[i] for i in test_metrics[\"y_pred_s\"]]\ndf_err[\"truth_true\"] = [idx2truth[i] for i in test_metrics[\"y_true_t\"]]\ndf_err[\"truth_pred\"] = [idx2truth[i] for i in test_metrics[\"y_pred_t\"]]\ndf_err[\"sent_correct\"] = (df_err[\"sent_true\"] == df_err[\"sent_pred\"]).astype(int)\ndf_err[\"truth_correct\"] = (df_err[\"truth_true\"] == df_err[\"truth_pred\"]).astype(int)\ndf_err[\"both_correct\"] = (df_err[\"sent_correct\"].eq(1) & df_err[\"truth_correct\"].eq(1)).astype(int)\n\nerr_path = os.path.join(SAVE_DIR, \"error_analysis_test.xlsx\")\nwith pd.ExcelWriter(err_path, engine=\"openpyxl\") as writer:\n    df_err.to_excel(writer, index=False, sheet_name=\"errors\")\nprint(\"Saved error analysis to:\", err_path)","metadata":{"_uuid":"369cfb77-f9a7-416a-98fd-6c645287b47a","_cell_guid":"253a4b69-09bf-4f0a-977e-8370725c0b10","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save inference config\ninference_config = {\n    \"max_length\": MAX_LENGTH,\n    \"sentiment_map\": SENTIMENT_MAP,\n    \"truth_map\": TRUTH_MAP,\n    \"model_type\": \"hierarchical-banglabert-multitask\",\n    \"alpha_sentiment\": ALPHA_SENTIMENT,\n    \"contrast_weight\": CONTRAST_WEIGHT,\n    \"class_weights\": sent_class_weights.tolist()\n}\n\nwith open(os.path.join(SAVE_DIR, \"inference_config.json\"), \"w\", encoding=\"utf-8\") as f:\n    json.dump(inference_config, f, ensure_ascii=False, indent=2)\n\nprint(\"✅ All artifacts saved to:\", SAVE_DIR)\nprint(\"🎉 Advanced training completed successfully!\")","metadata":{"_uuid":"84afc0f1-e111-4ccb-aa71-1c236358f53f","_cell_guid":"a57216c6-0473-4e01-b570-d5977bb340f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}